"""
åˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿæ¼”ç¤º

æ¼”ç¤ºRediså’Œå†…å­˜ç¼“å­˜çš„ä½¿ç”¨ã€‚
"""

import asyncio
import time
from ai_commit.cache.distributed_cache import (
    DistributedCacheManager, CacheBackend, get_distributed_cache_manager
)

async def demo_memory_cache():
    """æ¼”ç¤ºå†…å­˜ç¼“å­˜"""
    print("=== å†…å­˜ç¼“å­˜æ¼”ç¤º ===\n")
    
    # åˆ›å»ºå†…å­˜ç¼“å­˜ç®¡ç†å™¨
    cache_manager = DistributedCacheManager(CacheBackend.MEMORY, max_size=1000)
    
    # æ¼”ç¤ºåŸºæœ¬æ“ä½œ
    print("1. åŸºæœ¬ç¼“å­˜æ“ä½œ...")
    
    # è®¾ç½®å€¼
    await cache_manager.set("key1", "value1", ttl=10)
    await cache_manager.set("key2", {"data": "complex"}, ttl=10)
    await cache_manager.set("key3", [1, 2, 3, 4, 5], ttl=10)
    
    print("   âœ… ç¼“å­˜å€¼å·²è®¾ç½®")
    
    # è·å–å€¼
    value1 = await cache_manager.get("key1")
    value2 = await cache_manager.get("key2")
    value3 = await cache_manager.get("key3")
    
    print(f"   è·å–çš„å€¼:")
    print(f"     key1: {value1}")
    print(f"     key2: {value2}")
    print(f"     key3: {value3}")
    
    # æ£€æŸ¥å­˜åœ¨æ€§
    exists = await cache_manager.exists("key1")
    print(f"   key1 å­˜åœ¨: {exists}")
    
    # åˆ é™¤å€¼
    deleted = await cache_manager.delete("key1")
    print(f"   åˆ é™¤ key1: {deleted}")
    
    # å†æ¬¡æ£€æŸ¥å­˜åœ¨æ€§
    exists = await cache_manager.exists("key1")
    print(f"   key1 å­˜åœ¨: {exists}")
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = await cache_manager.get_stats()
    print(f"\n2. ç¼“å­˜ç»Ÿè®¡:")
    print(f"   åç«¯: {stats['backend']}")
    print(f"   å‘½ä¸­ç‡: {stats['manager_stats']['hit_rate']:.2%}")
    print(f"   æ“ä½œæ•°: {stats['manager_stats']['operations']}")
    print(f"   å¹³å‡å»¶è¿Ÿ: {stats['manager_stats']['avg_latency_ms']:.3f}ms")
    print(f"   å¥åº·æ£€æŸ¥: {stats['health_check']}")
    
    # æ¸…ç†
    await cache_manager.cleanup()
    print("\n   âœ… å†…å­˜ç¼“å­˜æ¼”ç¤ºå®Œæˆ")


async def demo_redis_cache():
    """æ¼”ç¤ºRedisç¼“å­˜"""
    print("\n=== Redisç¼“å­˜æ¼”ç¤º ===\n")
    
    try:
        # åˆ›å»ºRedisç¼“å­˜ç®¡ç†å™¨
        cache_manager = DistributedCacheManager(
            CacheBackend.REDIS,
            host='localhost',
            port=6379,
            db=0
        )
        
        # å¥åº·æ£€æŸ¥
        healthy = await cache_manager.health_check()
        print(f"1. Rediså¥åº·æ£€æŸ¥: {'âœ… å¥åº·' if healthy else 'âŒ ä¸å¥åº·'}")
        
        if not healthy:
            print("   âš ï¸  RedisæœåŠ¡ä¸å¯ç”¨ï¼Œè·³è¿‡Redisæ¼”ç¤º")
            await cache_manager.cleanup()
            return
        
        # æ¼”ç¤ºåŸºæœ¬æ“ä½œ
        print("\n2. åŸºæœ¬ç¼“å­˜æ“ä½œ...")
        
        # è®¾ç½®ä¸åŒç±»å‹çš„å€¼
        await cache_manager.set("string_key", "Hello Redis!", ttl=60)
        await cache_manager.set("dict_key", {"name": "AI Commit", "version": "1.0.0"}, ttl=60)
        await cache_manager.set("list_key", [1, 2, 3, 4, 5], ttl=60)
        await cache_manager.set("complex_key", {
            "users": ["alice", "bob", "charlie"],
            "settings": {"theme": "dark", "language": "en"}
        }, ttl=60)
        
        print("   âœ… å„ç§ç±»å‹çš„å€¼å·²è®¾ç½®")
        
        # è·å–å€¼
        string_val = await cache_manager.get("string_key")
        dict_val = await cache_manager.get("dict_key")
        list_val = await cache_manager.get("list_key")
        complex_val = await cache_manager.get("complex_key")
        
        print(f"   è·å–çš„å€¼:")
        print(f"     string_key: {string_val}")
        print(f"     dict_key: {dict_val}")
        print(f"     list_key: {list_val}")
        print(f"     complex_key: {complex_val}")
        
        # æ¼”ç¤ºTTL
        print("\n3. TTLæ¼”ç¤º...")
        await cache_manager.set("ttl_key", "This will expire", ttl=2)
        print("   è®¾ç½®2ç§’TTLçš„é”®")
        
        # ç«‹å³è·å–
        exists_before = await cache_manager.exists("ttl_key")
        print(f"   ç«‹å³æ£€æŸ¥å­˜åœ¨æ€§: {exists_before}")
        
        # ç­‰å¾…3ç§’
        print("   ç­‰å¾…3ç§’...")
        await asyncio.sleep(3)
        
        # å†æ¬¡æ£€æŸ¥
        exists_after = await cache_manager.exists("ttl_key")
        value_after = await cache_manager.get("ttl_key")
        print(f"   3ç§’åå­˜åœ¨æ€§: {exists_after}")
        print(f"   3ç§’åå€¼: {value_after}")
        
        # æ€§èƒ½æµ‹è¯•
        print("\n4. æ€§èƒ½æµ‹è¯•...")
        
        # æ‰¹é‡æ“ä½œ
        start_time = time.time()
        
        for i in range(100):
            await cache_manager.set(f"perf_key_{i}", f"value_{i}", ttl=60)
        
        set_time = time.time() - start_time
        
        start_time = time.time()
        
        for i in range(100):
            await cache_manager.get(f"perf_key_{i}")
        
        get_time = time.time() - start_time
        
        print(f"   æ‰¹é‡è®¾ç½®100ä¸ªé”®: {set_time:.3f}s")
        print(f"   æ‰¹é‡è·å–100ä¸ªé”®: {get_time:.3f}s")
        print(f"   å¹³å‡è®¾ç½®æ—¶é—´: {set_time/100*1000:.3f}ms")
        print(f"   å¹³å‡è·å–æ—¶é—´: {get_time/100*1000:.3f}ms")
        
        # è·å–ç»Ÿè®¡ä¿¡æ¯
        stats = await cache_manager.get_stats()
        print(f"\n5. Redisç¼“å­˜ç»Ÿè®¡:")
        print(f"   åç«¯: {stats['backend']}")
        print(f"   å‘½ä¸­ç‡: {stats['manager_stats']['hit_rate']:.2%}")
        print(f"   æ“ä½œæ•°: {stats['manager_stats']['operations']}")
        print(f"   å¹³å‡å»¶è¿Ÿ: {stats['manager_stats']['avg_latency_ms']:.3f}ms")
        print(f"   å¥åº·æ£€æŸ¥: {stats['health_check']}")
        
        # æ¸…ç†
        print("\n6. æ¸…ç†...")
        await cache_manager.clear()
        print("   âœ… Redisç¼“å­˜å·²æ¸…ç©º")
        
        await cache_manager.cleanup()
        print("   âœ… Redisç¼“å­˜æ¼”ç¤ºå®Œæˆ")
        
    except Exception as e:
        print(f"   âŒ Redisæ¼”ç¤ºå‡ºé”™: {e}")
        print("   âš ï¸  è¯·ç¡®ä¿RedisæœåŠ¡æ­£åœ¨è¿è¡Œ")


async def demo_cache_comparison():
    """æ¼”ç¤ºç¼“å­˜æ€§èƒ½å¯¹æ¯”"""
    print("\n=== ç¼“å­˜æ€§èƒ½å¯¹æ¯”æ¼”ç¤º ===\n")
    
    # åˆ›å»ºä¸åŒåç«¯çš„ç¼“å­˜ç®¡ç†å™¨
    memory_cache = DistributedCacheManager(CacheBackend.MEMORY, max_size=1000)
    
    try:
        redis_cache = DistributedCacheManager(
            CacheBackend.REDIS,
            host='localhost',
            port=6379,
            db=0
        )
        
        redis_available = await redis_cache.health_check()
    except Exception:
        redis_cache = None
        redis_available = False
    
    # æµ‹è¯•æ•°æ®
    test_data = {
        "user_id": 12345,
        "username": "test_user",
        "email": "test@example.com",
        "preferences": {
            "theme": "dark",
            "language": "en",
            "notifications": True
        },
        "metadata": {
            "created_at": "2024-01-01T00:00:00Z",
            "updated_at": "2024-01-01T00:00:00Z"
        }
    }
    
    # æµ‹è¯•æ¬¡æ•°
    test_iterations = 1000
    
    print(f"1. æ€§èƒ½å¯¹æ¯”æµ‹è¯• ({test_iterations} æ¬¡æ“ä½œ)...")
    
    # æµ‹è¯•å†…å­˜ç¼“å­˜
    print("\n   æµ‹è¯•å†…å­˜ç¼“å­˜...")
    start_time = time.time()
    
    for i in range(test_iterations):
        key = f"memory_test_{i % 100}"  # ä½¿ç”¨100ä¸ªä¸åŒçš„é”®
        await memory_cache.set(key, test_data, ttl=60)
        await memory_cache.get(key)
    
    memory_time = time.time() - start_time
    memory_stats = await memory_cache.get_stats()
    
    print(f"   å†…å­˜ç¼“å­˜æ€»æ—¶é—´: {memory_time:.3f}s")
    print(f"   å†…å­˜ç¼“å­˜å¹³å‡å»¶è¿Ÿ: {memory_time/test_iterations*1000:.3f}ms")
    print(f"   å†…å­˜ç¼“å­˜å‘½ä¸­ç‡: {memory_stats['manager_stats']['hit_rate']:.2%}")
    
    # æµ‹è¯•Redisç¼“å­˜
    if redis_available and redis_cache:
        print("\n   æµ‹è¯•Redisç¼“å­˜...")
        start_time = time.time()
        
        for i in range(test_iterations):
            key = f"redis_test_{i % 100}"  # ä½¿ç”¨100ä¸ªä¸åŒçš„é”®
            await redis_cache.set(key, test_data, ttl=60)
            await redis_cache.get(key)
        
        redis_time = time.time() - start_time
        redis_stats = await redis_cache.get_stats()
        
        print(f"   Redisç¼“å­˜æ€»æ—¶é—´: {redis_time:.3f}s")
        print(f"   Redisç¼“å­˜å¹³å‡å»¶è¿Ÿ: {redis_time/test_iterations*1000:.3f}ms")
        print(f"   Redisç¼“å­˜å‘½ä¸­ç‡: {redis_stats['manager_stats']['hit_rate']:.2%}")
        
        # æ€§èƒ½å¯¹æ¯”
        print(f"\n   æ€§èƒ½å¯¹æ¯”:")
        if redis_time > 0:
            speed_ratio = memory_time / redis_time
            print(f"   å†…å­˜ç¼“å­˜ vs Redis: {speed_ratio:.2f}x {'æ›´å¿«' if speed_ratio > 1 else 'æ›´æ…¢'}")
        
    else:
        print("\n   âš ï¸  Redisä¸å¯ç”¨ï¼Œè·³è¿‡Redisæµ‹è¯•")
    
    # æ¸…ç†
    await memory_cache.cleanup()
    if redis_cache:
        await redis_cache.cleanup()
    
    print("\n   âœ… ç¼“å­˜æ€§èƒ½å¯¹æ¯”æ¼”ç¤ºå®Œæˆ")


async def demo_cache_features():
    """æ¼”ç¤ºç¼“å­˜é«˜çº§ç‰¹æ€§"""
    print("\n=== ç¼“å­˜é«˜çº§ç‰¹æ€§æ¼”ç¤º ===\n")
    
    # åˆ›å»ºç¼“å­˜ç®¡ç†å™¨
    cache_manager = DistributedCacheManager(CacheBackend.MEMORY, max_size=500)
    
    print("1. ç¼“å­˜æ·˜æ±°ç­–ç•¥æ¼”ç¤º...")
    
    # è®¾ç½®å¤§é‡æ•°æ®è§¦å‘æ·˜æ±°
    print("   è®¾ç½®600ä¸ªæ•°æ®ç‚¹ï¼ˆç¼“å­˜å¤§å°é™åˆ¶ä¸º500ï¼‰...")
    for i in range(600):
        await cache_manager.set(f"eviction_test_{i}", f"value_{i}", ttl=60)
    
    # æ£€æŸ¥ä¸€äº›é”®æ˜¯å¦è¿˜å­˜åœ¨
    exists_early = await cache_manager.exists("eviction_test_10")
    exists_late = await cache_manager.exists("eviction_test_590")
    
    print(f"   æ—©æœŸé”®å­˜åœ¨: {exists_early}")
    print(f"   æ™šæœŸé”®å­˜åœ¨: {exists_late}")
    
    # è·å–ç»Ÿè®¡
    stats = await cache_manager.get_stats()
    print(f"   æ·˜æ±°æ¬¡æ•°: {stats['cache_stats']['evictions']}")
    
    print("\n2. ç¼“å­˜é”®ç”Ÿæˆç­–ç•¥æ¼”ç¤º...")
    
    # æ¼”ç¤ºä¸åŒçš„é”®ç”Ÿæˆç­–ç•¥
    import hashlib
    
    # ç®€å•é”®
    simple_key = "user:12345:profile"
    await cache_manager.set(simple_key, {"name": "Alice"}, ttl=60)
    
    # å“ˆå¸Œé”®
    complex_data = {"large": "data" * 100}
    hash_key = hashlib.md5(str(complex_data).encode()).hexdigest()[:16]
    await cache_manager.set(hash_key, complex_data, ttl=60)
    
    # ç»„åˆé”®
    combo_key = f"session:{hashlib.md5('user123'.encode()).hexdigest()[:8]}:data"
    await cache_manager.set(combo_key, {"session_id": "abc123"}, ttl=60)
    
    print(f"   ç®€å•é”®: {simple_key}")
    print(f"   å“ˆå¸Œé”®: {hash_key}")
    print(f"   ç»„åˆé”®: {combo_key}")
    
    # éªŒè¯é”®éƒ½å¯ä»¥è·å–
    simple_val = await cache_manager.get(simple_key)
    hash_val = await cache_manager.get(hash_key)
    combo_val = await cache_manager.get(combo_key)
    
    print(f"   ç®€å•é”®å€¼: {simple_val is not None}")
    print(f"   å“ˆå¸Œé”®å€¼: {hash_val is not None}")
    print(f"   ç»„åˆé”®å€¼: {combo_val is not None}")
    
    print("\n3. ç¼“å­˜å¥åº·æ£€æŸ¥æ¼”ç¤º...")
    
    # å¥åº·æ£€æŸ¥
    healthy = await cache_manager.health_check()
    print(f"   å¥åº·çŠ¶æ€: {'âœ… å¥åº·' if healthy else 'âŒ ä¸å¥åº·'}")
    
    # è·å–è¯¦ç»†ç»Ÿè®¡
    stats = await cache_manager.get_stats()
    print(f"   è¯¦ç»†ç»Ÿè®¡:")
    for key, value in stats['manager_stats'].items():
        if isinstance(value, float):
            print(f"     {key}: {value:.3f}")
        else:
            print(f"     {key}: {value}")
    
    # æ¸…ç†
    await cache_manager.cleanup()
    print("\n   âœ… ç¼“å­˜é«˜çº§ç‰¹æ€§æ¼”ç¤ºå®Œæˆ")


async def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("AI Commit åˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿæ¼”ç¤º")
    print("=" * 50)
    
    # å†…å­˜ç¼“å­˜æ¼”ç¤º
    await demo_memory_cache()
    
    # Redisç¼“å­˜æ¼”ç¤º
    await demo_redis_cache()
    
    # æ€§èƒ½å¯¹æ¯”æ¼”ç¤º
    await demo_cache_comparison()
    
    # é«˜çº§ç‰¹æ€§æ¼”ç¤º
    await demo_cache_features()
    
    print("\nğŸ‰ åˆ†å¸ƒå¼ç¼“å­˜ç³»ç»Ÿæ¼”ç¤ºå®Œæˆ!")


if __name__ == "__main__":
    asyncio.run(main())